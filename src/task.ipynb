{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import json\n",
    "import os\n",
    "from pycocotools.coco import COCO\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "lr = 0.001\n",
    "epochs = 5\n",
    "\n",
    "\n",
    "path_to_train_image = \"D:\\\\Studies\\\\ucenje\\\\keypoint_detection_coco\\\\data\\\\train2017\\\\\"\n",
    "path_to_train_anns = \"D:\\\\Studies\\\\ucenje\\\\keypoint_detection_coco\\\\data\\\\annotations\\\\coco_wholebody_train_v1.0.json\"\n",
    "path_to_val_image = \"D:\\\\Studies\\\\ucenje\\\\keypoint_detection_coco\\\\data\\\\val2017\\\\\"\n",
    "path_to_val_anns = \"D:\\\\Studies\\\\ucenje\\\\keypoint_detection_coco\\\\data\\\\annotations\\\\coco_wholebody_val_v1.0.json\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Prepare data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=46.26s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=1.59s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "class CocoDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, path_to_images, path_to_anns):\n",
    "        super(CocoDataset, self).__init__()\n",
    "        coco = COCO(path_to_anns)\n",
    "        self.anns = coco.loadAnns(coco.getAnnIds(imgIds=coco.getImgIds(catIds=[1]), catIds=[1]))\n",
    "        self.path_to_images = path_to_images\n",
    "\n",
    "        # Loading data from annotations and cleaning it to make a simple dataset\n",
    "        all_entries = [[self.anns[i][\"keypoints\"][j] for j in range(len(self.anns[i][\"keypoints\"])) if j % 3 != 0] for i in range(len(self.anns))]\n",
    "        for i in range(len(self.anns)):\n",
    "            all_entries[i].append(self.anns[i]['image_id'])\n",
    "\n",
    "        columns = np.array([\n",
    "            \"nose\",\n",
    "            \"left_eye\",\n",
    "            \"right_eye\",\n",
    "            \"left_ear\",\n",
    "            \"right_ear\",\n",
    "            \"left_shoulder\",\n",
    "            \"right_shoulder\",\n",
    "            \"left_elbow\",\n",
    "            \"right_elbow\",\n",
    "            \"left_wrist\",\n",
    "            \"right_wrist\",\n",
    "            \"left_hip\",\n",
    "            \"right_hip\",\n",
    "            \"left_knee\",\n",
    "            \"right_knee\",\n",
    "            \"left_ankle\",\n",
    "            \"right_ankle\"\n",
    "        ])\n",
    "\n",
    "        columns = [x for pair in zip(columns, columns) for x in pair]\n",
    "        for i in range(len(columns)):\n",
    "            if i % 2 == 0:\n",
    "                columns[i] = columns[i] + '.x'\n",
    "            else:\n",
    "                columns[i] = columns[i] + '.y'\n",
    "\n",
    "        columns = columns + [\"id\"]\n",
    "        all_entries_df = pd.DataFrame(all_entries, columns=columns)\n",
    "        self.data = all_entries_df[~(all_entries_df == 0).any(axis=1)].drop_duplicates(subset=[\"id\"])\n",
    "        # 6830 rows x 35 columns, (x,y) of specific keypoint * 17, id of image\n",
    "        # every image has one person on it\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image_id = str(self.data.id.iloc[index]).zfill(12) + '.jpg'\n",
    "        image = Image.open(self.path_to_images + image_id).convert(\"RGB\")\n",
    "        original_width, original_height = image.size\n",
    "        image = np.asarray(image.resize((384, 280)), dtype=\"float32\")\n",
    "        image = image / 255.\n",
    "        image = image.transpose(2, 0, 1)\n",
    "        keypoints = self.data.iloc[index][:34]\n",
    "        keypoints = np.array(keypoints, dtype=\"float32\")\n",
    "        keypoints = keypoints.reshape(-1, 2)\n",
    "        keypoints = keypoints * [384 / original_width, 280 / original_height]\n",
    "        return {\n",
    "            \"image\": torch.tensor(image, dtype=torch.float),\n",
    "            \"keypoints\": torch.tensor(keypoints, dtype=torch.float)\n",
    "        }\n",
    "\n",
    "\n",
    "train_data = CocoDataset(path_to_train_image, path_to_train_anns)\n",
    "val_data = CocoDataset(path_to_val_image, path_to_val_anns)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=4, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(val_data, batch_size=4, shuffle=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Create model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, 7)\n",
    "        self.pool = nn.MaxPool2d(2,2)\n",
    "        self.conv2 = nn.Conv2d(16, 32, 5)\n",
    "        self.conv3 = nn.Conv2d(32, 64, 3)\n",
    "        self.conv4 = nn.Conv2d(64, 128, 3)\n",
    "        self.linear1 = nn.LazyLinear(1000)\n",
    "        self.linear2 = nn.Linear(1000, 512)\n",
    "        self.linear3 = nn.Linear(512, 100)\n",
    "        self.linear4 = nn.Linear(100, 34)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = self.pool(F.relu(self.conv3(x)))\n",
    "        x = F.relu(self.conv4(x))\n",
    "        x = x.reshape(x.shape[0], -1)\n",
    "        x = F.relu(self.linear1(x))\n",
    "        x = F.relu(self.linear2(x))\n",
    "        x = F.relu(self.linear3(x))\n",
    "        x = self.linear4(x)\n",
    "        return x"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Train loop"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\envs\\pytorch_tutorial\\lib\\site-packages\\torch\\nn\\modules\\lazy.py:178: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=0\n",
      "epoch=1\n",
      "epoch=2\n",
      "epoch=3\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "model = SimpleCNN().to(device)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "train_loss = []\n",
    "running_loss = 0.0\n",
    "for epoch in range(epochs):\n",
    "    for i, data in enumerate(train_loader):\n",
    "        image, keypoints = data['image'].to(device), data[\"keypoints\"].to(device)\n",
    "        keypoints = keypoints.view(keypoints.size(0), -1)\n",
    "        preds = model(image)\n",
    "        loss = criterion(preds, keypoints)\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        train_loss.append(loss.item())\n",
    "    print(f\"epoch={epoch}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "running_loss / (len(train_data) / 4)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Eval loop"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "model.eval()\n",
    "val_loss = []\n",
    "val_running_loss = 0.0\n",
    "with torch.no_grad():\n",
    "    for i, data in enumerate(val_loader):\n",
    "        image, keypoints = data['image'].to(device), data['keypoints'].to(device)\n",
    "        keypoints = keypoints.view(keypoints.size(0), -1)\n",
    "        preds = model(image)\n",
    "        loss = criterion(preds, keypoints)\n",
    "        val_running_loss += loss.item()\n",
    "        val_loss.append(loss.item())\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "val_running_loss / (len(val_data) / 4)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pytorch_tutorial",
   "language": "python",
   "display_name": "pytorch_tutorial"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}