{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import json\n",
    "import os\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from math import ceil, floor\n",
    "from tqdm import tqdm\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "from torchinfo import summary"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Config"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "batch_size = 16\n",
    "epochs = 10\n",
    "lr = 0.001\n",
    "split_size = 0.8\n",
    "\n",
    "path_to_anns = \"D:\\\\Studies\\\\ucenje\\\\keypoint_flickr\\\\data\\\\annotations\\\\all_data.json\"\n",
    "path_to_img = \"D:\\\\Studies\\\\ucenje\\\\keypoint_flickr\\\\data\\\\images\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Datasets and Dataloaders"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "class FlickrDatasetClassification(Dataset):\n",
    "    def __init__(self, path_to_anns, path_to_imgs, transform=None):\n",
    "        with open(path_to_anns, 'r') as f:\n",
    "            self.anns = json.loads(f.read())\n",
    "        self.image_path = path_to_imgs\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.anns)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.image_path, self.anns[str(idx)][\"file_name\"])\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        orig_width, orig_height = image.size\n",
    "\n",
    "        image.thumbnail((224, 224))\n",
    "        image = np.array(image, dtype=np.uint8)\n",
    "        keypoints = np.array(self.anns[str(idx)][\"face_landmarks\"], dtype=np.float32)\n",
    "        keypoints = keypoints.clip(min=0, max=orig_height if orig_height >= orig_width else orig_width)\n",
    "        keypoints = keypoints * [224.0 / orig_width, 224.0 / orig_height]\n",
    "        keypoints = keypoints.astype('uint8')\n",
    "        new_keypoints = torch.zeros(68, 224, 224)\n",
    "        for i in range(len(new_keypoints)):\n",
    "            new_keypoints[i][keypoints[i][0]-1][keypoints[i][1]-1] = 1\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, new_keypoints, idx\n",
    "\n",
    "dataset_classification = FlickrDatasetClassification(path_to_anns,path_to_img,\n",
    "                        transform=transforms.ToTensor())\n",
    "train_len = ceil(len(dataset_classification) * split_size)\n",
    "val_len = ceil(len(dataset_classification) * (1-split_size))\n",
    "train_dataset_classification, val_dataset_classification = torch.utils.data.random_split(dataset_classification, (train_len, val_len))\n",
    "train_loader_classification = DataLoader(train_dataset_classification, batch_size=batch_size, shuffle=True)\n",
    "val_loader_classification = DataLoader(val_dataset_classification, batch_size=1, shuffle=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Utils"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def plot_img_classification(predictions): # predictions list of tuple (index, predicted_keypoints)\n",
    "    transform = transforms.ToPILImage() # transform tensor back to PILImage\n",
    "\n",
    "    images, original_keypoints_list, predicted_keypoints_list = [], [], []\n",
    "\n",
    "    for i, data in enumerate(predictions):\n",
    "        image = dataset_classification[data[0].item()][0]\n",
    "        image = transform(image.cpu().detach())  # Images to PIL, keypoints to numpy array\n",
    "        images.append(image)\n",
    "        original_keypoints = dataset_classification[data[0].item()][1]\n",
    "        original_keypoints = original_keypoints.cpu().detach().numpy().reshape(-1, 2)\n",
    "        original_keypoints_list.append(original_keypoints)\n",
    "        predicted_keypoints = data[1].cpu().detach()\n",
    "        predicted_keypoints = np.reshape(predicted_keypoints, (1,2,0))\n",
    "        print(predicted_keypoints)\n",
    "        for i in range(224):\n",
    "            for j in range(224):\n",
    "                index_of_keypoint = np.argmax(predicted_keypoints[i][j])\n",
    "                max_of_keypoints = np.max(predicted_keypoints[i][j])\n",
    "                if max_of_keypoints > .50:\n",
    "                    predicted_keypoints_list.append((i, j))\n",
    "\n",
    "    original_keypoints_list = np.array(original_keypoints_list)\n",
    "    predicted_keypoints_list = np.array(predicted_keypoints_list)\n",
    "\n",
    "    plt.figure(figsize=(40,80))\n",
    "    for i in range(40):\n",
    "        plt.subplot(20, 2, i + 1)\n",
    "        plt.imshow(images[i // 2])\n",
    "        if i % 2 == 0:\n",
    "            for p in range(original_keypoints_list[i//2].shape[0]):\n",
    "                plt.plot(original_keypoints_list[i//2][p, 0], original_keypoints_list[i//2][p, 1], 'g.')\n",
    "        else:\n",
    "            for p in range(predicted_keypoints_list[i//2].shape[0]):\n",
    "                plt.plot(predicted_keypoints_list[i//2][p, 0], predicted_keypoints_list[i//2][p, 1], 'g.')\n",
    "    print(predicted_keypoints_list[0])\n",
    "    print(print(predictions[0][1]))\n",
    "    plt.plot()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Classification Model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "class ClassificationCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ClassificationCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, 3)\n",
    "        self.conv2 = nn.Conv2d(16, 32, 3)\n",
    "        self.conv3 = nn.Conv2d(32, 68, 5)\n",
    "        self.batch1 = nn.BatchNorm2d(16)\n",
    "        self.batch2 = nn.BatchNorm2d(32)\n",
    "        self.batch3 = nn.BatchNorm2d(68)\n",
    "        self.pool = nn.MaxPool2d(2,2)\n",
    "        self.upsample1 = nn.Upsample(size=(50, 50), mode=\"bicubic\")\n",
    "        self.upsample2 = nn.Upsample(size=(110, 110), mode=\"bicubic\")\n",
    "        self.upsample3 = nn.Upsample(size=(224, 224), mode=\"bicubic\")\n",
    "    def forward(self, x):\n",
    "        x = self.batch1(self.pool(F.relu(self.conv1(x))))\n",
    "        x = self.batch2(self.pool(F.relu(self.conv2(x))))\n",
    "        x = self.batch3(self.pool(F.relu(self.conv3(x))))\n",
    "        x = self.upsample1(x)\n",
    "        x = self.upsample2(x)\n",
    "        x = self.upsample3(x)\n",
    "        return x"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Training loop for regression"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Classification Model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "class FlickrDatasetClassification(Dataset):\n",
    "    def __init__(self, path_to_anns, path_to_imgs, transform=None):\n",
    "        with open(path_to_anns, 'r') as f:\n",
    "            self.anns = json.loads(f.read())\n",
    "        self.image_path = path_to_imgs\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.anns)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.image_path, self.anns[str(idx)][\"file_name\"])\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        orig_width, orig_height = image.size\n",
    "\n",
    "        image.thumbnail((224, 224))\n",
    "        image = np.array(image, dtype=np.uint8)\n",
    "        keypoints = np.array(self.anns[str(idx)][\"face_landmarks\"], dtype=np.float32)\n",
    "        keypoints = keypoints.clip(min=0, max=orig_height if orig_height >= orig_width else orig_width)\n",
    "        keypoints = keypoints * [224.0 / orig_width, 224.0 / orig_height]\n",
    "        keypoints = keypoints.astype('uint8')\n",
    "        new_keypoints = torch.zeros(68, 224, 224)\n",
    "        for i in range(len(new_keypoints)):\n",
    "            new_keypoints[i][keypoints[i][0]-1][keypoints[i][1]-1] = 1\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, new_keypoints, idx\n",
    "\n",
    "dataset_classification = FlickrDatasetClassification(path_to_anns,path_to_img,\n",
    "                                                     transform=transforms.ToTensor())\n",
    "train_len = ceil(len(dataset_classification) * split_size)\n",
    "val_len = ceil(len(dataset_classification) * (1-split_size))\n",
    "train_dataset_classification, val_dataset_classification = torch.utils.data.random_split(dataset_classification, (train_len, val_len))\n",
    "train_loader_classification = DataLoader(train_dataset_classification, batch_size=batch_size, shuffle=True)\n",
    "val_loader_classification = DataLoader(val_dataset_classification, batch_size=1, shuffle=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "==========================================================================================\nLayer (type:depth-idx)                   Output Shape              Param #\n==========================================================================================\nClassificationCNN                        [16, 68, 224, 224]        --\n├─Conv2d: 1-1                            [16, 16, 222, 222]        448\n├─MaxPool2d: 1-2                         [16, 16, 111, 111]        --\n├─BatchNorm2d: 1-3                       [16, 16, 111, 111]        32\n├─Conv2d: 1-4                            [16, 32, 109, 109]        4,640\n├─MaxPool2d: 1-5                         [16, 32, 54, 54]          --\n├─BatchNorm2d: 1-6                       [16, 32, 54, 54]          64\n├─Conv2d: 1-7                            [16, 68, 50, 50]          54,468\n├─MaxPool2d: 1-8                         [16, 68, 25, 25]          --\n├─BatchNorm2d: 1-9                       [16, 68, 25, 25]          136\n├─Upsample: 1-10                         [16, 68, 50, 50]          --\n├─Upsample: 1-11                         [16, 68, 110, 110]        --\n├─Upsample: 1-12                         [16, 68, 224, 224]        --\n==========================================================================================\nTotal params: 59,788\nTrainable params: 59,788\nNon-trainable params: 0\nTotal mult-adds (G): 3.41\n==========================================================================================\nInput size (MB): 9.63\nForward/backward pass size (MB): 213.98\nParams size (MB): 0.24\nEstimated Total Size (MB): 223.85\n=========================================================================================="
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ClassificationCNN().to(device)\n",
    "summary(model, input_size=(batch_size, 3, 224, 224))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [01:29<00:00,  2.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "Train_loss at epoch 1: 0.0042826280351728205\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [01:30<00:00,  2.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2\n",
      "Train_loss at epoch 2: 0.003575248851440847\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [01:31<00:00,  2.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3\n",
      "Train_loss at epoch 3: 0.0033735656328499316\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [01:31<00:00,  2.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4\n",
      "Train_loss at epoch 4: 0.003272678516805172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [01:33<00:00,  2.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5\n",
      "Train_loss at epoch 5: 0.003195893209427595\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [01:29<00:00,  2.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6\n",
      "Train_loss at epoch 6: 0.0031523521151393652\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [01:28<00:00,  2.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7\n",
      "Train_loss at epoch 7: 0.003101418474689126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [01:30<00:00,  2.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8\n",
      "Train_loss at epoch 8: 0.0030718903969973324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [01:30<00:00,  2.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9\n",
      "Train_loss at epoch 9: 0.0030454199090600015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [01:32<00:00,  2.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10\n",
      "Train_loss at epoch 10: 0.003022938188165426\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "#model = ClassificationCNN().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "train_loss = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    train_running_loss = 0.0\n",
    "    for i, data in tqdm(enumerate(train_loader_classification), total=(len(train_loader_classification))):\n",
    "        images, keypoints = data[0].to(device, dtype=torch.float32), data[1].to(device, dtype=torch.float32)\n",
    "        preds = model(images)\n",
    "        loss = criterion(preds, keypoints)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        train_running_loss += loss.item()\n",
    "    train_loss.append(train_running_loss / (ceil(len(train_dataset_classification) / batch_size)))\n",
    "\n",
    "    #model.eval()\n",
    "\n",
    "    #with torch.no_grad():\n",
    "    #    val_running_loss = 0.0\n",
    "    #    for i, data in tqdm(enumerate(val_loader), total=(len(val_loader))):\n",
    "    #        image, keypoints = data[0].to(device), data[1].to(device)\n",
    "    #        preds = model(image)\n",
    "    #        loss = criterion(preds, keypoints)\n",
    "    #        val_running_loss += loss.item()\n",
    "    #    val_loss.append(val_running_loss / ceil(len(val_dataset) / batch_size))\n",
    "    print(f'Epoch: {epoch + 1}')\n",
    "    print(f'Train_loss at epoch {epoch + 1}: {train_loss[-1]}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 1080x504 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(15,7))\n",
    "plt.plot(train_loss, label=\"train\")\n",
    "plt.xlabel(\"iterations\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 14.00 MiB (GPU 0; 11.00 GiB total capacity; 10.26 GiB already allocated; 0 bytes free; 10.33 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Input \u001B[1;32mIn [10]\u001B[0m, in \u001B[0;36m<cell line: 4>\u001B[1;34m()\u001B[0m\n\u001B[0;32m      5\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i, data \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(val_loader_classification):\n\u001B[0;32m      6\u001B[0m     images, keypoints, index \u001B[38;5;241m=\u001B[39m data[\u001B[38;5;241m0\u001B[39m]\u001B[38;5;241m.\u001B[39mto(device), data[\u001B[38;5;241m1\u001B[39m]\u001B[38;5;241m.\u001B[39mto(device), data[\u001B[38;5;241m2\u001B[39m]\n\u001B[1;32m----> 7\u001B[0m     pred \u001B[38;5;241m=\u001B[39m \u001B[43msoft\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[43mimages\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      8\u001B[0m     predictions\u001B[38;5;241m.\u001B[39mappend((index, pred))\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\pytorch_tutorial\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1126\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1127\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1128\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1129\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1130\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39m\u001B[38;5;28minput\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1131\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1132\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\pytorch_tutorial\\lib\\site-packages\\torch\\nn\\modules\\activation.py:1376\u001B[0m, in \u001B[0;36mSoftmax.forward\u001B[1;34m(self, input)\u001B[0m\n\u001B[0;32m   1375\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m: Tensor) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tensor:\n\u001B[1;32m-> 1376\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mF\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msoftmax\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdim\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m_stacklevel\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m5\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\pytorch_tutorial\\lib\\site-packages\\torch\\nn\\functional.py:1834\u001B[0m, in \u001B[0;36msoftmax\u001B[1;34m(input, dim, _stacklevel, dtype)\u001B[0m\n\u001B[0;32m   1832\u001B[0m     dim \u001B[38;5;241m=\u001B[39m _get_softmax_dim(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msoftmax\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28minput\u001B[39m\u001B[38;5;241m.\u001B[39mdim(), _stacklevel)\n\u001B[0;32m   1833\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m dtype \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m-> 1834\u001B[0m     ret \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43minput\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msoftmax\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdim\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1835\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   1836\u001B[0m     ret \u001B[38;5;241m=\u001B[39m \u001B[38;5;28minput\u001B[39m\u001B[38;5;241m.\u001B[39msoftmax(dim, dtype\u001B[38;5;241m=\u001B[39mdtype)\n",
      "\u001B[1;31mRuntimeError\u001B[0m: CUDA out of memory. Tried to allocate 14.00 MiB (GPU 0; 11.00 GiB total capacity; 10.26 GiB already allocated; 0 bytes free; 10.33 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "predictions = []\n",
    "soft = nn.Softmax(dim=1)\n",
    "with torch.no_grad():\n",
    "    for i, data in enumerate(val_loader_classification):\n",
    "        images, keypoints, index = data[0].to(device), data[1].to(device), data[2]\n",
    "        pred = soft(model(images))\n",
    "        predictions.append((index, pred))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot_img_classification(predictions)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pytorch_tutorial",
   "language": "python",
   "display_name": "pytorch_tutorial"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}