{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import json\n",
    "import os\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from math import ceil\n",
    "from tqdm import tqdm\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "from torchinfo import summary"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Dataset and Dataloader"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "batch_size = 32\n",
    "epochs = 25\n",
    "lr = 0.0005\n",
    "split_size = 0.9\n",
    "\n",
    "path_to_anns = \"D:\\\\Studies\\\\ucenje\\\\keypoint_flickr\\\\data\\\\annotations\\\\all_data.json\"\n",
    "path_to_img = \"D:\\\\Studies\\\\ucenje\\\\keypoint_flickr\\\\data\\\\images\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "class FlickrDatasetRegression(Dataset):\n",
    "    def __init__(self, path_to_anns, path_to_imgs, transform=None):\n",
    "        with open(path_to_anns, 'r') as f:\n",
    "            self.anns = json.loads(f.read())\n",
    "        self.image_path = path_to_imgs\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.anns)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.image_path, self.anns[str(idx)][\"file_name\"])\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        orig_width, orig_height = image.size\n",
    "        image.thumbnail((224, 224))\n",
    "        image = np.array(image, dtype=np.uint8)\n",
    "        keypoints = np.array(self.anns[str(idx)][\"face_landmarks\"])\n",
    "        keypoints = keypoints * [224 / orig_width, 224 / orig_height]\n",
    "        keypoints = keypoints.flatten()\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, torch.tensor(keypoints), idx\n",
    "\n",
    "dataset = FlickrDatasetRegression(path_to_anns,path_to_img,\n",
    "                        transform=transforms.ToTensor())\n",
    "train_len = ceil(len(dataset) * split_size)\n",
    "val_len = ceil(len(dataset) * (1-split_size))\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(dataset, (train_len, val_len))\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=1, shuffle=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Create Model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.conv = nn.Conv2d(3, 16, 9)\n",
    "        self.pool = nn.MaxPool2d(2,2)\n",
    "        self.norm = nn.BatchNorm2d(16)\n",
    "        self.linear1 = nn.LazyLinear(2048)\n",
    "        self.linear2 = nn.Linear(2048, 136)\n",
    "    def forward(self, x):\n",
    "        x = self.norm(self.pool(F.relu(self.conv(x))))\n",
    "        x = x.reshape(x.shape[0], -1)\n",
    "        x = F.relu(self.linear1(x))\n",
    "        x = self.linear2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class SimpleCNN2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN2, self).__init__()\n",
    "        self.pool = nn.MaxPool2d(2,2)\n",
    "        self.conv1 = nn.Conv2d(3, 32, 3)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 2)\n",
    "        self.conv3 = nn.Conv2d(64, 128, 2)\n",
    "        self.norm1 = nn.BatchNorm2d(32)\n",
    "        self.norm2 = nn.BatchNorm2d(64)\n",
    "        self.linear1 = nn.LazyLinear(1000)\n",
    "        self.linear2 = nn.Linear(1000, 256)\n",
    "        self.linear3 = nn.Linear(256, 136)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.norm1(self.pool(F.relu(self.conv1(x))))\n",
    "        x = self.norm2(self.pool(F.relu(self.conv2(x))))\n",
    "        x = self.pool(F.relu(self.conv3(x)))\n",
    "        x = x.reshape(x.shape[0], -1)\n",
    "        x = F.relu(self.linear1(x))\n",
    "        x = F.relu(self.linear2(x))\n",
    "        x = self.linear3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class ClassificationCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ClassificationCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, 3)\n",
    "        self.conv2 = nn.Conv2d(16, 32, 3)\n",
    "        self.conv3 = nn.Conv2d(32, 64, 5)\n",
    "        self.batch1 = nn.BatchNorm2d(16)\n",
    "        self.batch2 = nn.BatchNorm2d(32)\n",
    "        self.batch3 = nn.BatchNorm2d(64)\n",
    "        self.pool = nn.MaxPool2d(2,2)\n",
    "        self.conv_trans1 = nn.ConvTranspose2d(64, 32, 5)  # 30\n",
    "        self.conv_trans2 = nn.ConvTranspose2d(32, 16, 3)  # 58\n",
    "        self.conv_trans3 = nn.ConvTranspose2d(16, 68, 3)  # 114\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.batch1(self.pool(F.relu(self.conv1(x))))\n",
    "        x = self.batch2(self.pool(F.relu(self.conv2(x))))\n",
    "        x = self.batch3(self.pool(F.relu(self.conv3(x))))\n",
    "        x = F.relu(self.conv_trans1(x))\n",
    "        x = F.relu(self.conv_trans2(x))\n",
    "        x = F.relu(self.conv_trans3(x))\n",
    "        return x"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    " Train loop for simple CNN"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "model = SimpleCNN().to(device)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "train_loss = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    train_running_loss = 0.0\n",
    "    for i, data in tqdm(enumerate(train_loader), total=(len(train_loader))):\n",
    "        images, keypoints = data[0].to(device, dtype=torch.float32), data[1].to(device, dtype=torch.float32)\n",
    "        preds = model(images)\n",
    "        loss = criterion(preds, keypoints)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        train_running_loss += loss.item()\n",
    "    train_loss.append(train_running_loss / (ceil(len(train_dataset) / batch_size)))\n",
    "\n",
    "    #model.eval()\n",
    "\n",
    "    #with torch.no_grad():\n",
    "    #    val_running_loss = 0.0\n",
    "    #    for i, data in tqdm(enumerate(val_loader), total=(len(val_loader))):\n",
    "    #        image, keypoints = data[0].to(device), data[1].to(device)\n",
    "    #        preds = model(image)\n",
    "    #        loss = criterion(preds, keypoints)\n",
    "    #        val_running_loss += loss.item()\n",
    "    #    val_loss.append(val_running_loss / ceil(len(val_dataset) / batch_size))\n",
    "    print(f'Epoch: {epoch + 1}')\n",
    "    print(f'Train_loss at epoch {epoch + 1}: {train_loss[-1]}')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Plot loss"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,7))\n",
    "plt.plot(train_loss, label=\"train\")\n",
    "plt.xlabel(\"iterations\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Find top 10 best and worst performing images"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "val_losses = []\n",
    "with torch.no_grad():\n",
    "    for i, data in tqdm(enumerate(val_loader), total=(len(val_loader))):\n",
    "        image, keypoints, index = data[0].to(device), data[1].to(device), data[2]\n",
    "        pred = model(image)\n",
    "        loss = criterion(pred, keypoints)\n",
    "        val_losses.append((index, loss.item())) # (index, loss)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def get_top_images_dataloader(losses, dataset):\n",
    "    sorted_loss = sorted(losses, key = lambda x: x[1])\n",
    "    dataset_to_plot = sorted_loss[:10] + sorted_loss[-10:]\n",
    "    indexes_to_plot = [x[0].item() for x in dataset_to_plot]\n",
    "    new_data = [dataset[index] for index in indexes_to_plot]\n",
    "    dataloader_for_plots = DataLoader(new_data, batch_size=1, shuffle=False)\n",
    "    return dataloader_for_plots"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dataloader_for_plots = get_top_images_dataloader(val_losses, dataset)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "'(' was never closed (1144211643.py, line 6)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;36m  Input \u001B[1;32mIn [14]\u001B[1;36m\u001B[0m\n\u001B[1;33m    pred = model(image\u001B[0m\n\u001B[1;37m                ^\u001B[0m\n\u001B[1;31mSyntaxError\u001B[0m\u001B[1;31m:\u001B[0m '(' was never closed\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model.eval()\n",
    "predictions = []\n",
    "with torch.no_grad():\n",
    "    for i, data in enumerate(dataloader_for_plots):\n",
    "        images, keypoints, index = data[0].to(device), data[1].to(device), data[2]\n",
    "        pred = model(image)\n",
    "        predictions.append((index, pred))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def plot_img(predictions): # predictions list of tuple (index, predicted_keypoints)\n",
    "    transform = transforms.ToPILImage() # transform tensor back to PILImage\n",
    "\n",
    "    images, original_keypoints_list, predicted_keypoints_list = [], [], []\n",
    "\n",
    "    for i, data in enumerate(predictions):\n",
    "        image = dataset[data[0].item()][0]\n",
    "        image = transform(image.cpu().detach())  # Images to PIL, keypoints to numpy array\n",
    "        images.append(image)\n",
    "        original_keypoints = dataset[data[0].item()][1]\n",
    "        original_keypoints = original_keypoints.cpu().detach().numpy().reshape(-1, 2)\n",
    "        original_keypoints_list.append(original_keypoints)\n",
    "        predicted_keypoints = data[1].cpu().detach().numpy().reshape(-1, 2)\n",
    "        predicted_keypoints_list.append(predicted_keypoints)\n",
    "\n",
    "    original_keypoints_list = np.array(original_keypoints_list)\n",
    "    predicted_keypoints_list = np.array(predicted_keypoints_list)\n",
    "\n",
    "    plt.figure(figsize=(25,60))\n",
    "\n",
    "    for i in range(len(images) * 2):\n",
    "        plt.subplot(20, 2, i + 1)\n",
    "        plt.imshow(images[i // 2])\n",
    "        if i % 2 == 0:\n",
    "            for p in range(original_keypoints_list[i//2].shape[0]):\n",
    "                plt.plot(original_keypoints_list[i//2][p, 0], original_keypoints_list[i//2][p, 1], 'g.')\n",
    "        else:\n",
    "            for p in range(predicted_keypoints_list[i//2].shape[0]):\n",
    "                plt.plot(predicted_keypoints_list[i//2][p, 0], predicted_keypoints_list[i//2][p, 1], 'g.')\n",
    "    plt.plot()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot_img(predictions)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "class FlickrDatasetClassification(Dataset):\n",
    "    def __init__(self, path_to_anns, path_to_imgs, transform=None):\n",
    "        with open(path_to_anns, 'r') as f:\n",
    "            self.anns = json.loads(f.read())\n",
    "        self.image_path = path_to_imgs\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.anns)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.image_path, self.anns[str(idx)][\"file_name\"])\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        orig_width, orig_height = image.size\n",
    "        image.thumbnail((224, 224))\n",
    "        image = np.array(image, dtype=np.uint8)\n",
    "        keypoints = np.array(self.anns[str(idx)][\"face_landmarks\"])\n",
    "        keypoints = keypoints * [224 / orig_width, 224 / orig_height]\n",
    "        keypoints = keypoints.astype('uint8')\n",
    "        print(keypoints)\n",
    "        new_keypoints = torch.zeros(68, 224, 224)\n",
    "        for i in range(len(new_keypoints)):\n",
    "            new_keypoints[i][keypoints[i][0]][keypoints[i][1]] = 1\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, new_keypoints, idx\n",
    "\n",
    "dataset_classification = FlickrDatasetClassification(path_to_anns,path_to_img,\n",
    "                        transform=transforms.ToTensor())\n",
    "train_len = ceil(len(dataset_classification) * split_size)\n",
    "val_len = ceil(len(dataset_classification) * (1-split_size))\n",
    "train_dataset_classification, val_dataset_classification = torch.utils.data.random_split(dataset_classification, (train_len, val_len))\n",
    "train_loader_classification = DataLoader(train_dataset_classification, batch_size=batch_size, shuffle=True)\n",
    "val_loader_classification = DataLoader(val_dataset_classification, batch_size=batch_size, shuffle=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "==========================================================================================\nLayer (type:depth-idx)                   Output Shape              Param #\n==========================================================================================\nClassificationCNN                        [32, 68, 33, 33]          --\n├─Conv2d: 1-1                            [32, 16, 222, 222]        448\n├─MaxPool2d: 1-2                         [32, 16, 111, 111]        --\n├─BatchNorm2d: 1-3                       [32, 16, 111, 111]        32\n├─Conv2d: 1-4                            [32, 32, 109, 109]        4,640\n├─MaxPool2d: 1-5                         [32, 32, 54, 54]          --\n├─BatchNorm2d: 1-6                       [32, 32, 54, 54]          64\n├─Conv2d: 1-7                            [32, 64, 50, 50]          51,264\n├─MaxPool2d: 1-8                         [32, 64, 25, 25]          --\n├─BatchNorm2d: 1-9                       [32, 64, 25, 25]          128\n├─ConvTranspose2d: 1-10                  [32, 32, 29, 29]          51,232\n├─ConvTranspose2d: 1-11                  [32, 16, 31, 31]          4,624\n├─ConvTranspose2d: 1-12                  [32, 68, 33, 33]          9,860\n==========================================================================================\nTotal params: 122,292\nTrainable params: 122,292\nNon-trainable params: 0\nTotal mult-adds (G): 8.44\n==========================================================================================\nInput size (MB): 19.27\nForward/backward pass size (MB): 454.53\nParams size (MB): 0.49\nEstimated Total Size (MB): 474.29\n=========================================================================================="
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ClassificationCNN().to(device)\n",
    "summary(model, input_size=(batch_size, 3, 224, 224))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/141 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 59 113]\n",
      " [ 60 127]\n",
      " [ 62 140]\n",
      " [ 65 153]\n",
      " [ 71 166]\n",
      " [ 80 176]\n",
      " [ 90 185]\n",
      " [101 193]\n",
      " [113 196]\n",
      " [127 193]\n",
      " [143 186]\n",
      " [158 179]\n",
      " [171 168]\n",
      " [178 153]\n",
      " [181 137]\n",
      " [181 121]\n",
      " [182 105]\n",
      " [ 64 103]\n",
      " [ 69  97]\n",
      " [ 78  95]\n",
      " [ 87  96]\n",
      " [ 96  98]\n",
      " [120  96]\n",
      " [130  93]\n",
      " [141  91]\n",
      " [152  91]\n",
      " [162  95]\n",
      " [108 107]\n",
      " [108 115]\n",
      " [108 123]\n",
      " [108 131]\n",
      " [ 99 138]\n",
      " [104 140]\n",
      " [110 141]\n",
      " [116 139]\n",
      " [123 137]\n",
      " [ 76 110]\n",
      " [ 82 107]\n",
      " [ 89 106]\n",
      " [ 95 110]\n",
      " [ 89 111]\n",
      " [ 82 111]\n",
      " [128 107]\n",
      " [134 103]\n",
      " [141 102]\n",
      " [148 105]\n",
      " [141 107]\n",
      " [135 107]\n",
      " [ 87 153]\n",
      " [ 96 152]\n",
      " [105 150]\n",
      " [112 151]\n",
      " [119 149]\n",
      " [131 149]\n",
      " [144 150]\n",
      " [133 160]\n",
      " [121 164]\n",
      " [113 165]\n",
      " [106 165]\n",
      " [ 97 162]\n",
      " [ 91 154]\n",
      " [105 153]\n",
      " [112 153]\n",
      " [120 152]\n",
      " [141 151]\n",
      " [121 159]\n",
      " [113 159]\n",
      " [106 159]]\n",
      "[[ 46 104]\n",
      " [ 48 120]\n",
      " [ 50 137]\n",
      " [ 52 152]\n",
      " [ 56 168]\n",
      " [ 64 182]\n",
      " [ 76 192]\n",
      " [ 90 201]\n",
      " [106 204]\n",
      " [122 200]\n",
      " [134 191]\n",
      " [146 181]\n",
      " [154 168]\n",
      " [157 154]\n",
      " [159 139]\n",
      " [160 126]\n",
      " [161 112]\n",
      " [ 63  90]\n",
      " [ 70  83]\n",
      " [ 81  79]\n",
      " [ 92  80]\n",
      " [100  87]\n",
      " [129  89]\n",
      " [137  84]\n",
      " [146  85]\n",
      " [155  89]\n",
      " [159  98]\n",
      " [115 104]\n",
      " [115 114]\n",
      " [115 125]\n",
      " [116 135]\n",
      " [101 140]\n",
      " [107 143]\n",
      " [113 146]\n",
      " [119 144]\n",
      " [124 142]\n",
      " [ 75 103]\n",
      " [ 83 100]\n",
      " [ 91 101]\n",
      " [ 98 108]\n",
      " [ 90 109]\n",
      " [ 81 108]\n",
      " [127 110]\n",
      " [134 104]\n",
      " [142 104]\n",
      " [147 109]\n",
      " [142 112]\n",
      " [134 111]\n",
      " [ 78 155]\n",
      " [ 91 152]\n",
      " [103 152]\n",
      " [112 154]\n",
      " [120 153]\n",
      " [128 154]\n",
      " [136 157]\n",
      " [127 168]\n",
      " [118 172]\n",
      " [110 172]\n",
      " [101 171]\n",
      " [ 89 166]\n",
      " [ 82 156]\n",
      " [103 157]\n",
      " [111 158]\n",
      " [119 157]\n",
      " [132 158]\n",
      " [118 166]\n",
      " [110 167]\n",
      " [102 166]]\n",
      "[[ 48 106]\n",
      " [ 47 121]\n",
      " [ 48 137]\n",
      " [ 49 152]\n",
      " [ 54 166]\n",
      " [ 64 178]\n",
      " [ 77 187]\n",
      " [ 91 193]\n",
      " [106 197]\n",
      " [121 195]\n",
      " [134 188]\n",
      " [146 179]\n",
      " [155 168]\n",
      " [160 155]\n",
      " [162 141]\n",
      " [163 128]\n",
      " [164 115]\n",
      " [ 63  98]\n",
      " [ 72  91]\n",
      " [ 83  89]\n",
      " [ 95  91]\n",
      " [105  96]\n",
      " [127  99]\n",
      " [136  96]\n",
      " [145  96]\n",
      " [154  99]\n",
      " [159 106]\n",
      " [115 105]\n",
      " [114 113]\n",
      " [114 120]\n",
      " [114 129]\n",
      " [ 99 135]\n",
      " [105 137]\n",
      " [112 139]\n",
      " [118 138]\n",
      " [123 137]\n",
      " [ 77 104]\n",
      " [ 84 102]\n",
      " [ 90 103]\n",
      " [ 96 107]\n",
      " [ 89 106]\n",
      " [ 83 106]\n",
      " [128 110]\n",
      " [135 107]\n",
      " [141 108]\n",
      " [147 111]\n",
      " [141 111]\n",
      " [134 111]\n",
      " [ 81 151]\n",
      " [ 93 149]\n",
      " [103 149]\n",
      " [110 150]\n",
      " [117 149]\n",
      " [126 151]\n",
      " [134 155]\n",
      " [126 164]\n",
      " [116 166]\n",
      " [109 166]\n",
      " [101 165]\n",
      " [ 91 161]\n",
      " [ 85 152]\n",
      " [103 152]\n",
      " [110 153]\n",
      " [117 153]\n",
      " [131 156]\n",
      " [117 161]\n",
      " [109 161]\n",
      " [102 160]]\n",
      "[[ 55  92]\n",
      " [ 55 108]\n",
      " [ 56 125]\n",
      " [ 58 141]\n",
      " [ 64 155]\n",
      " [ 74 169]\n",
      " [ 83 183]\n",
      " [ 93 195]\n",
      " [107 200]\n",
      " [121 198]\n",
      " [135 188]\n",
      " [146 176]\n",
      " [157 162]\n",
      " [165 148]\n",
      " [169 133]\n",
      " [172 117]\n",
      " [174 100]\n",
      " [ 64  88]\n",
      " [ 73  84]\n",
      " [ 83  84]\n",
      " [ 93  87]\n",
      " [103  91]\n",
      " [121  94]\n",
      " [132  91]\n",
      " [144  91]\n",
      " [154  93]\n",
      " [163  99]\n",
      " [111 106]\n",
      " [110 118]\n",
      " [109 130]\n",
      " [108 142]\n",
      " [ 95 142]\n",
      " [102 145]\n",
      " [108 148]\n",
      " [115 146]\n",
      " [122 145]\n",
      " [ 76 103]\n",
      " [ 83 103]\n",
      " [ 90 104]\n",
      " [ 95 106]\n",
      " [ 89 106]\n",
      " [ 82 105]\n",
      " [128 109]\n",
      " [135 108]\n",
      " [141 108]\n",
      " [148 109]\n",
      " [141 110]\n",
      " [135 110]\n",
      " [ 83 151]\n",
      " [ 93 153]\n",
      " [102 154]\n",
      " [108 156]\n",
      " [115 155]\n",
      " [125 156]\n",
      " [134 156]\n",
      " [124 170]\n",
      " [114 176]\n",
      " [107 177]\n",
      " [ 99 175]\n",
      " [ 91 167]\n",
      " [ 86 154]\n",
      " [102 158]\n",
      " [108 160]\n",
      " [114 160]\n",
      " [131 157]\n",
      " [114 168]\n",
      " [107 168]\n",
      " [101 166]]\n",
      "[[ 72 109]\n",
      " [ 67 120]\n",
      " [ 65 133]\n",
      " [ 67 146]\n",
      " [ 70 161]\n",
      " [ 73 175]\n",
      " [ 78 190]\n",
      " [ 84 204]\n",
      " [ 97 210]\n",
      " [115 212]\n",
      " [136 207]\n",
      " [157 201]\n",
      " [176 190]\n",
      " [189 175]\n",
      " [196 156]\n",
      " [199 136]\n",
      " [201 117]\n",
      " [ 72  84]\n",
      " [ 75  79]\n",
      " [ 81  79]\n",
      " [ 88  82]\n",
      " [ 93  86]\n",
      " [117  87]\n",
      " [128  82]\n",
      " [141  80]\n",
      " [154  83]\n",
      " [164  91]\n",
      " [102 103]\n",
      " [ 99 112]\n",
      " [ 95 121]\n",
      " [ 91 130]\n",
      " [ 86 140]\n",
      " [ 90 143]\n",
      " [ 96 145]\n",
      " [104 143]\n",
      " [113 141]\n",
      " [ 77 105]\n",
      " [ 82 100]\n",
      " [ 90 100]\n",
      " [ 96 107]\n",
      " [ 89 108]\n",
      " [ 81 108]\n",
      " [126 108]\n",
      " [134 102]\n",
      " [143 102]\n",
      " [150 108]\n",
      " [143 110]\n",
      " [134 110]\n",
      " [ 81 162]\n",
      " [ 85 154]\n",
      " [ 91 151]\n",
      " [ 97 153]\n",
      " [104 152]\n",
      " [118 156]\n",
      " [132 164]\n",
      " [118 174]\n",
      " [104 178]\n",
      " [ 97 178]\n",
      " [ 90 177]\n",
      " [ 85 172]\n",
      " [ 85 163]\n",
      " [ 91 159]\n",
      " [ 97 159]\n",
      " [104 160]\n",
      " [127 165]\n",
      " [104 168]\n",
      " [ 97 168]\n",
      " [ 91 167]]\n",
      "[[ 38 107]\n",
      " [ 38 125]\n",
      " [ 40 142]\n",
      " [ 43 159]\n",
      " [ 50 175]\n",
      " [ 62 187]\n",
      " [ 77 197]\n",
      " [ 94 204]\n",
      " [111 205]\n",
      " [127 201]\n",
      " [139 192]\n",
      " [149 181]\n",
      " [156 168]\n",
      " [161 155]\n",
      " [163 141]\n",
      " [164 127]\n",
      " [163 112]\n",
      " [ 59  97]\n",
      " [ 70  90]\n",
      " [ 84  87]\n",
      " [ 97  89]\n",
      " [109  95]\n",
      " [123  95]\n",
      " [132  91]\n",
      " [144  89]\n",
      " [154  92]\n",
      " [159 100]\n",
      " [116 103]\n",
      " [117 114]\n",
      " [118 125]\n",
      " [119 136]\n",
      " [100 142]\n",
      " [108 145]\n",
      " [116 147]\n",
      " [123 145]\n",
      " [128 142]\n",
      " [ 74 106]\n",
      " [ 82 103]\n",
      " [ 89 103]\n",
      " [ 97 107]\n",
      " [ 89 107]\n",
      " [ 82 107]\n",
      " [128 108]\n",
      " [135 105]\n",
      " [142 105]\n",
      " [149 108]\n",
      " [142 108]\n",
      " [135 108]\n",
      " [ 80 159]\n",
      " [ 93 157]\n",
      " [105 156]\n",
      " [113 158]\n",
      " [119 156]\n",
      " [128 157]\n",
      " [136 159]\n",
      " [128 170]\n",
      " [119 175]\n",
      " [112 176]\n",
      " [104 175]\n",
      " [ 92 170]\n",
      " [ 83 159]\n",
      " [105 160]\n",
      " [112 161]\n",
      " [119 160]\n",
      " [132 160]\n",
      " [119 168]\n",
      " [112 170]\n",
      " [105 169]]\n",
      "[[ 57 109]\n",
      " [ 57 124]\n",
      " [ 59 139]\n",
      " [ 60 155]\n",
      " [ 65 170]\n",
      " [ 71 183]\n",
      " [ 81 194]\n",
      " [ 92 201]\n",
      " [107 204]\n",
      " [122 202]\n",
      " [136 198]\n",
      " [149 189]\n",
      " [159 178]\n",
      " [165 163]\n",
      " [169 147]\n",
      " [173 131]\n",
      " [175 115]\n",
      " [ 65  94]\n",
      " [ 70  88]\n",
      " [ 80  85]\n",
      " [ 89  86]\n",
      " [ 98  89]\n",
      " [124  89]\n",
      " [135  87]\n",
      " [146  87]\n",
      " [155  91]\n",
      " [162  99]\n",
      " [110 103]\n",
      " [110 112]\n",
      " [110 123]\n",
      " [109 133]\n",
      " [ 98 139]\n",
      " [103 141]\n",
      " [109 144]\n",
      " [115 142]\n",
      " [120 141]\n",
      " [ 75 105]\n",
      " [ 81 101]\n",
      " [ 89 102]\n",
      " [ 96 107]\n",
      " [ 89 108]\n",
      " [ 81 108]\n",
      " [128 108]\n",
      " [135 104]\n",
      " [143 104]\n",
      " [149 109]\n",
      " [142 110]\n",
      " [135 110]\n",
      " [ 85 159]\n",
      " [ 93 152]\n",
      " [102 151]\n",
      " [109 152]\n",
      " [116 152]\n",
      " [126 154]\n",
      " [134 161]\n",
      " [126 171]\n",
      " [115 174]\n",
      " [107 175]\n",
      " [100 173]\n",
      " [ 91 170]\n",
      " [ 89 159]\n",
      " [102 156]\n",
      " [108 157]\n",
      " [116 157]\n",
      " [131 161]\n",
      " [116 168]\n",
      " [108 168]\n",
      " [101 167]]\n",
      "[[ 44 102]\n",
      " [ 44 120]\n",
      " [ 46 138]\n",
      " [ 49 155]\n",
      " [ 56 171]\n",
      " [ 67 183]\n",
      " [ 80 194]\n",
      " [ 95 203]\n",
      " [110 205]\n",
      " [124 202]\n",
      " [135 193]\n",
      " [144 182]\n",
      " [152 169]\n",
      " [157 154]\n",
      " [161 139]\n",
      " [164 123]\n",
      " [165 107]\n",
      " [ 62  97]\n",
      " [ 70  89]\n",
      " [ 82  86]\n",
      " [ 94  89]\n",
      " [106  93]\n",
      " [122  95]\n",
      " [133  92]\n",
      " [143  90]\n",
      " [154  92]\n",
      " [159 100]\n",
      " [113 106]\n",
      " [114 117]\n",
      " [114 128]\n",
      " [115 139]\n",
      " [101 145]\n",
      " [107 147]\n",
      " [114 148]\n",
      " [120 147]\n",
      " [126 145]\n",
      " [ 75 104]\n",
      " [ 83 101]\n",
      " [ 90 101]\n",
      " [ 96 107]\n",
      " [ 89 107]\n",
      " [ 82 107]\n",
      " [128 108]\n",
      " [134 103]\n",
      " [141 104]\n",
      " [147 107]\n",
      " [142 109]\n",
      " [134 109]\n",
      " [ 88 165]\n",
      " [ 98 162]\n",
      " [107 160]\n",
      " [113 161]\n",
      " [118 160]\n",
      " [125 162]\n",
      " [131 166]\n",
      " [125 172]\n",
      " [118 175]\n",
      " [112 176]\n",
      " [106 176]\n",
      " [ 97 173]\n",
      " [ 92 166]\n",
      " [106 165]\n",
      " [112 166]\n",
      " [118 165]\n",
      " [127 166]\n",
      " [118 167]\n",
      " [113 168]\n",
      " [107 168]]\n",
      "[[ 28 113]\n",
      " [ 29 131]\n",
      " [ 31 149]\n",
      " [ 36 168]\n",
      " [ 50 183]\n",
      " [ 67 193]\n",
      " [ 86 201]\n",
      " [106 204]\n",
      " [121 202]\n",
      " [130 197]\n",
      " [135 188]\n",
      " [140 174]\n",
      " [144 162]\n",
      " [146 149]\n",
      " [148 135]\n",
      " [146 122]\n",
      " [142 110]\n",
      " [ 67  94]\n",
      " [ 76  87]\n",
      " [ 89  83]\n",
      " [102  83]\n",
      " [114  86]\n",
      " [127  88]\n",
      " [132  85]\n",
      " [137  84]\n",
      " [141  85]\n",
      " [143  89]\n",
      " [121 102]\n",
      " [124 110]\n",
      " [128 119]\n",
      " [133 128]\n",
      " [111 138]\n",
      " [119 140]\n",
      " [127 141]\n",
      " [133 139]\n",
      " [138 136]\n",
      " [ 77 106]\n",
      " [ 85 104]\n",
      " [ 92 103]\n",
      " [ 99 107]\n",
      " [ 92 109]\n",
      " [ 84 109]\n",
      " [126 106]\n",
      " [131 103]\n",
      " [137 102]\n",
      " [140 105]\n",
      " [137 107]\n",
      " [131 107]\n",
      " [ 96 166]\n",
      " [108 156]\n",
      " [121 151]\n",
      " [127 152]\n",
      " [131 150]\n",
      " [136 154]\n",
      " [136 163]\n",
      " [135 170]\n",
      " [131 175]\n",
      " [126 176]\n",
      " [120 176]\n",
      " [108 174]\n",
      " [100 165]\n",
      " [120 159]\n",
      " [126 158]\n",
      " [131 158]\n",
      " [133 163]\n",
      " [131 165]\n",
      " [126 166]\n",
      " [120 166]]\n",
      "[[ 62 111]\n",
      " [ 64 123]\n",
      " [ 67 135]\n",
      " [ 71 147]\n",
      " [ 78 158]\n",
      " [ 86 168]\n",
      " [ 95 178]\n",
      " [106 186]\n",
      " [119 188]\n",
      " [133 185]\n",
      " [143 176]\n",
      " [151 166]\n",
      " [156 153]\n",
      " [159 140]\n",
      " [160 127]\n",
      " [161 113]\n",
      " [160  99]\n",
      " [ 65  95]\n",
      " [ 71  90]\n",
      " [ 80  90]\n",
      " [ 89  91]\n",
      " [ 98  95]\n",
      " [120  93]\n",
      " [128  88]\n",
      " [137  84]\n",
      " [147  83]\n",
      " [154  87]\n",
      " [111 106]\n",
      " [112 116]\n",
      " [113 126]\n",
      " [114 137]\n",
      " [103 142]\n",
      " [109 144]\n",
      " [115 145]\n",
      " [121 143]\n",
      " [126 141]\n",
      " [ 76 109]\n",
      " [ 82 106]\n",
      " [ 89 105]\n",
      " [ 95 109]\n",
      " [ 89 111]\n",
      " [ 82 112]\n",
      " [127 107]\n",
      " [132 102]\n",
      " [139 101]\n",
      " [145 103]\n",
      " [141 107]\n",
      " [134 108]\n",
      " [ 97 158]\n",
      " [103 155]\n",
      " [111 153]\n",
      " [116 154]\n",
      " [122 152]\n",
      " [130 153]\n",
      " [136 154]\n",
      " [131 163]\n",
      " [124 168]\n",
      " [118 169]\n",
      " [111 169]\n",
      " [104 165]\n",
      " [101 159]\n",
      " [111 160]\n",
      " [116 160]\n",
      " [122 159]\n",
      " [133 156]\n",
      " [123 159]\n",
      " [117 161]\n",
      " [111 160]]\n",
      "[[ 60 118]\n",
      " [ 62 131]\n",
      " [ 66 143]\n",
      " [ 70 156]\n",
      " [ 76 167]\n",
      " [ 86 176]\n",
      " [ 99 181]\n",
      " [112 186]\n",
      " [125 187]\n",
      " [137 183]\n",
      " [149 176]\n",
      " [159 168]\n",
      " [167 156]\n",
      " [170 143]\n",
      " [172 129]\n",
      " [172 114]\n",
      " [170  99]\n",
      " [ 67 106]\n",
      " [ 71  99]\n",
      " [ 80  95]\n",
      " [ 89  95]\n",
      " [ 98  97]\n",
      " [116  95]\n",
      " [125  90]\n",
      " [135  86]\n",
      " [146  87]\n",
      " [155  92]\n",
      " [109 107]\n",
      " [110 114]\n",
      " [111 121]\n",
      " [112 128]\n",
      " [105 137]\n",
      " [110 138]\n",
      " [114 138]\n",
      " [119 137]\n",
      " [124 134]\n",
      " [ 78 113]\n",
      " [ 83 107]\n",
      " [ 89 106]\n",
      " [ 96 111]\n",
      " [ 90 113]\n",
      " [ 83 113]\n",
      " [125 107]\n",
      " [131 100]\n",
      " [138  99]\n",
      " [145 102]\n",
      " [139 105]\n",
      " [132 106]\n",
      " [100 156]\n",
      " [105 149]\n",
      " [111 145]\n",
      " [116 145]\n",
      " [120 143]\n",
      " [128 145]\n",
      " [137 150]\n",
      " [130 156]\n",
      " [123 160]\n",
      " [118 161]\n",
      " [113 161]\n",
      " [106 161]\n",
      " [102 155]\n",
      " [112 150]\n",
      " [117 149]\n",
      " [121 148]\n",
      " [133 150]\n",
      " [122 154]\n",
      " [117 155]\n",
      " [112 156]]\n",
      "[[ 69 104]\n",
      " [ 65 116]\n",
      " [ 64 130]\n",
      " [ 65 143]\n",
      " [ 68 157]\n",
      " [ 71 171]\n",
      " [ 76 183]\n",
      " [ 83 194]\n",
      " [ 95 200]\n",
      " [111 203]\n",
      " [130 201]\n",
      " [149 194]\n",
      " [163 182]\n",
      " [174 168]\n",
      " [181 151]\n",
      " [186 133]\n",
      " [189 114]\n",
      " [ 71  90]\n",
      " [ 75  86]\n",
      " [ 83  87]\n",
      " [ 91  91]\n",
      " [ 99  96]\n",
      " [118  98]\n",
      " [130  95]\n",
      " [143  95]\n",
      " [155  97]\n",
      " [166 105]\n",
      " [105 106]\n",
      " [102 115]\n",
      " [ 99 124]\n",
      " [ 96 133]\n",
      " [ 90 138]\n",
      " [ 94 141]\n",
      " [ 98 144]\n",
      " [105 143]\n",
      " [112 142]\n",
      " [ 78 102]\n",
      " [ 83  98]\n",
      " [ 91  99]\n",
      " [ 98 107]\n",
      " [ 89 107]\n",
      " [ 82 106]\n",
      " [126 111]\n",
      " [133 105]\n",
      " [142 106]\n",
      " [149 112]\n",
      " [141 113]\n",
      " [132 113]\n",
      " [ 84 153]\n",
      " [ 89 151]\n",
      " [ 95 152]\n",
      " [100 153]\n",
      " [105 153]\n",
      " [117 156]\n",
      " [131 161]\n",
      " [117 168]\n",
      " [105 169]\n",
      " [ 99 169]\n",
      " [ 93 167]\n",
      " [ 88 162]\n",
      " [ 87 154]\n",
      " [ 94 154]\n",
      " [ 99 156]\n",
      " [105 156]\n",
      " [127 160]\n",
      " [105 163]\n",
      " [100 162]\n",
      " [ 95 160]]\n",
      "[[ 36 106]\n",
      " [ 37 123]\n",
      " [ 40 140]\n",
      " [ 45 155]\n",
      " [ 55 169]\n",
      " [ 69 180]\n",
      " [ 85 188]\n",
      " [101 195]\n",
      " [116 196]\n",
      " [127 192]\n",
      " [134 181]\n",
      " [140 170]\n",
      " [145 158]\n",
      " [149 144]\n",
      " [152 131]\n",
      " [152 118]\n",
      " [151 105]\n",
      " [ 62  93]\n",
      " [ 72  87]\n",
      " [ 84  86]\n",
      " [ 95  89]\n",
      " [106  93]\n",
      " [124  93]\n",
      " [132  89]\n",
      " [140  86]\n",
      " [148  85]\n",
      " [153  90]\n",
      " [117 105]\n",
      " [119 114]\n",
      " [122 123]\n",
      " [124 133]\n",
      " [109 143]\n",
      " [115 144]\n",
      " [121 145]\n",
      " [126 143]\n",
      " [130 140]\n",
      " [ 76 107]\n",
      " [ 83 104]\n",
      " [ 91 103]\n",
      " [ 97 108]\n",
      " [ 91 111]\n",
      " [ 83 110]\n",
      " [126 106]\n",
      " [132 101]\n",
      " [139 100]\n",
      " [143 103]\n",
      " [140 107]\n",
      " [133 107]\n",
      " [ 98 166]\n",
      " [106 161]\n",
      " [114 157]\n",
      " [120 159]\n",
      " [125 157]\n",
      " [130 159]\n",
      " [133 163]\n",
      " [130 167]\n",
      " [125 171]\n",
      " [120 172]\n",
      " [114 172]\n",
      " [106 170]\n",
      " [102 165]\n",
      " [114 162]\n",
      " [120 163]\n",
      " [125 161]\n",
      " [130 162]\n",
      " [125 163]\n",
      " [120 164]\n",
      " [115 164]]\n",
      "[[ 64 109]\n",
      " [ 66 122]\n",
      " [ 68 135]\n",
      " [ 69 148]\n",
      " [ 72 161]\n",
      " [ 80 172]\n",
      " [ 89 181]\n",
      " [100 189]\n",
      " [113 192]\n",
      " [127 190]\n",
      " [140 183]\n",
      " [151 174]\n",
      " [159 161]\n",
      " [164 147]\n",
      " [165 131]\n",
      " [167 116]\n",
      " [168 101]\n",
      " [ 64  99]\n",
      " [ 68  90]\n",
      " [ 77  88]\n",
      " [ 86  90]\n",
      " [ 96  93]\n",
      " [119  90]\n",
      " [130  85]\n",
      " [141  83]\n",
      " [153  84]\n",
      " [161  93]\n",
      " [108 105]\n",
      " [109 116]\n",
      " [109 126]\n",
      " [109 136]\n",
      " [ 98 142]\n",
      " [104 143]\n",
      " [110 144]\n",
      " [116 143]\n",
      " [123 141]\n",
      " [ 75 109]\n",
      " [ 81 105]\n",
      " [ 89 105]\n",
      " [ 95 110]\n",
      " [ 88 112]\n",
      " [ 81 112]\n",
      " [126 108]\n",
      " [134 103]\n",
      " [141 102]\n",
      " [148 105]\n",
      " [142 109]\n",
      " [134 109]\n",
      " [ 88 150]\n",
      " [ 97 151]\n",
      " [105 151]\n",
      " [111 153]\n",
      " [118 151]\n",
      " [128 151]\n",
      " [141 150]\n",
      " [129 160]\n",
      " [118 163]\n",
      " [111 164]\n",
      " [105 162]\n",
      " [ 97 158]\n",
      " [ 91 151]\n",
      " [105 155]\n",
      " [111 156]\n",
      " [118 155]\n",
      " [138 151]\n",
      " [118 157]\n",
      " [111 157]\n",
      " [105 156]]\n",
      "[[ 45 109]\n",
      " [ 46 126]\n",
      " [ 48 144]\n",
      " [ 51 161]\n",
      " [ 59 177]\n",
      " [ 72 189]\n",
      " [ 88 198]\n",
      " [105 204]\n",
      " [121 204]\n",
      " [134 200]\n",
      " [144 188]\n",
      " [153 175]\n",
      " [159 161]\n",
      " [161 146]\n",
      " [163 130]\n",
      " [164 114]\n",
      " [164  98]\n",
      " [ 60 103]\n",
      " [ 69  96]\n",
      " [ 82  94]\n",
      " [ 94  95]\n",
      " [107  98]\n",
      " [122  96]\n",
      " [132  93]\n",
      " [141  90]\n",
      " [152  89]\n",
      " [158  95]\n",
      " [114 105]\n",
      " [116 118]\n",
      " [118 130]\n",
      " [120 142]\n",
      " [105 149]\n",
      " [112 149]\n",
      " [119 151]\n",
      " [125 149]\n",
      " [129 146]\n",
      " [ 75 108]\n",
      " [ 81 104]\n",
      " [ 89 104]\n",
      " [ 96 109]\n",
      " [ 89 111]\n",
      " [ 81 111]\n",
      " [127 106]\n",
      " [133 100]\n",
      " [141  99]\n",
      " [147 103]\n",
      " [141 107]\n",
      " [134 107]\n",
      " [ 90 167]\n",
      " [102 166]\n",
      " [112 164]\n",
      " [118 166]\n",
      " [124 163]\n",
      " [131 163]\n",
      " [138 162]\n",
      " [132 169]\n",
      " [125 172]\n",
      " [119 174]\n",
      " [113 174]\n",
      " [102 172]\n",
      " [ 93 167]\n",
      " [112 168]\n",
      " [118 168]\n",
      " [124 166]\n",
      " [135 163]\n",
      " [125 166]\n",
      " [119 168]\n",
      " [113 168]]\n",
      "[[ 59  97]\n",
      " [ 58 112]\n",
      " [ 58 126]\n",
      " [ 57 141]\n",
      " [ 59 156]\n",
      " [ 65 169]\n",
      " [ 74 181]\n",
      " [ 84 192]\n",
      " [ 97 198]\n",
      " [111 198]\n",
      " [127 193]\n",
      " [140 185]\n",
      " [151 174]\n",
      " [158 160]\n",
      " [162 145]\n",
      " [167 130]\n",
      " [172 113]\n",
      " [ 68  92]\n",
      " [ 75  87]\n",
      " [ 86  87]\n",
      " [ 96  91]\n",
      " [104  96]\n",
      " [123  99]\n",
      " [133  96]\n",
      " [143  96]\n",
      " [153  99]\n",
      " [160 106]\n",
      " [111 106]\n",
      " [109 116]\n",
      " [107 126]\n",
      " [105 136]\n",
      " [ 95 138]\n",
      " [ 99 142]\n",
      " [105 145]\n",
      " [111 144]\n",
      " [118 142]\n",
      " [ 78 102]\n",
      " [ 85 100]\n",
      " [ 92 101]\n",
      " [ 98 106]\n",
      " [ 90 105]\n",
      " [ 83 104]\n",
      " [127 110]\n",
      " [134 108]\n",
      " [140 109]\n",
      " [146 112]\n",
      " [139 113]\n",
      " [133 112]\n",
      " [ 80 149]\n",
      " [ 88 149]\n",
      " [ 97 151]\n",
      " [104 153]\n",
      " [112 153]\n",
      " [123 154]\n",
      " [133 158]\n",
      " [122 167]\n",
      " [110 170]\n",
      " [102 170]\n",
      " [ 94 168]\n",
      " [ 85 161]\n",
      " [ 82 150]\n",
      " [ 96 154]\n",
      " [104 157]\n",
      " [111 157]\n",
      " [130 158]\n",
      " [111 165]\n",
      " [103 164]\n",
      " [ 95 162]]\n",
      "[[ 26 107]\n",
      " [ 26 127]\n",
      " [ 28 147]\n",
      " [ 34 166]\n",
      " [ 45 182]\n",
      " [ 60 194]\n",
      " [ 78 205]\n",
      " [ 97 212]\n",
      " [114 212]\n",
      " [126 206]\n",
      " [134 193]\n",
      " [140 180]\n",
      " [146 166]\n",
      " [151 151]\n",
      " [155 136]\n",
      " [156 122]\n",
      " [155 106]\n",
      " [ 60  97]\n",
      " [ 70  89]\n",
      " [ 83  84]\n",
      " [ 97  84]\n",
      " [109  87]\n",
      " [125  85]\n",
      " [133  80]\n",
      " [142  78]\n",
      " [150  80]\n",
      " [153  88]\n",
      " [117 104]\n",
      " [119 116]\n",
      " [121 128]\n",
      " [123 140]\n",
      " [105 147]\n",
      " [112 149]\n",
      " [119 151]\n",
      " [125 149]\n",
      " [130 145]\n",
      " [ 73 109]\n",
      " [ 81 104]\n",
      " [ 90 104]\n",
      " [ 96 109]\n",
      " [ 90 110]\n",
      " [ 81 111]\n",
      " [127 106]\n",
      " [135 100]\n",
      " [142  99]\n",
      " [146 103]\n",
      " [143 106]\n",
      " [135 107]\n",
      " [ 87 168]\n",
      " [ 99 163]\n",
      " [111 161]\n",
      " [117 162]\n",
      " [124 160]\n",
      " [131 161]\n",
      " [136 163]\n",
      " [131 176]\n",
      " [124 184]\n",
      " [117 186]\n",
      " [110 186]\n",
      " [ 98 181]\n",
      " [ 91 168]\n",
      " [111 165]\n",
      " [117 165]\n",
      " [124 164]\n",
      " [132 165]\n",
      " [124 173]\n",
      " [117 176]\n",
      " [110 176]]\n",
      "[[ 56 117]\n",
      " [ 56 132]\n",
      " [ 58 147]\n",
      " [ 61 161]\n",
      " [ 67 175]\n",
      " [ 74 187]\n",
      " [ 85 196]\n",
      " [ 96 203]\n",
      " [111 205]\n",
      " [125 203]\n",
      " [141 198]\n",
      " [155 190]\n",
      " [166 178]\n",
      " [173 163]\n",
      " [177 147]\n",
      " [180 130]\n",
      " [180 113]\n",
      " [ 62  97]\n",
      " [ 67  87]\n",
      " [ 76  81]\n",
      " [ 88  79]\n",
      " [ 98  83]\n",
      " [116  81]\n",
      " [128  76]\n",
      " [142  76]\n",
      " [155  82]\n",
      " [163  93]\n",
      " [106 100]\n",
      " [106 106]\n",
      " [105 112]\n",
      " [105 118]\n",
      " [ 97 137]\n",
      " [102 137]\n",
      " [107 137]\n",
      " [112 137]\n",
      " [118 136]\n",
      " [ 73 109]\n",
      " [ 80 102]\n",
      " [ 89 101]\n",
      " [ 95 108]\n",
      " [ 89 111]\n",
      " [ 80 111]\n",
      " [126 106]\n",
      " [134  99]\n",
      " [143  99]\n",
      " [151 105]\n",
      " [144 108]\n",
      " [134 108]\n",
      " [ 94 167]\n",
      " [ 99 158]\n",
      " [105 153]\n",
      " [108 154]\n",
      " [112 152]\n",
      " [121 156]\n",
      " [129 165]\n",
      " [122 172]\n",
      " [114 175]\n",
      " [110 175]\n",
      " [106 175]\n",
      " [100 173]\n",
      " [ 98 165]\n",
      " [105 159]\n",
      " [109 159]\n",
      " [112 158]\n",
      " [125 164]\n",
      " [113 168]\n",
      " [109 169]\n",
      " [106 168]]\n",
      "[[ 57  99]\n",
      " [ 56 114]\n",
      " [ 56 128]\n",
      " [ 57 142]\n",
      " [ 61 155]\n",
      " [ 67 168]\n",
      " [ 75 179]\n",
      " [ 85 189]\n",
      " [ 98 193]\n",
      " [112 193]\n",
      " [124 187]\n",
      " [136 180]\n",
      " [147 172]\n",
      " [154 160]\n",
      " [159 148]\n",
      " [163 134]\n",
      " [167 119]\n",
      " [ 68  96]\n",
      " [ 76  89]\n",
      " [ 88  88]\n",
      " [ 98  92]\n",
      " [108  98]\n",
      " [121 102]\n",
      " [132 100]\n",
      " [143 100]\n",
      " [153 103]\n",
      " [159 112]\n",
      " [113 107]\n",
      " [112 115]\n",
      " [110 122]\n",
      " [109 130]\n",
      " [ 96 135]\n",
      " [102 137]\n",
      " [107 140]\n",
      " [114 139]\n",
      " [120 139]\n",
      " [ 80 101]\n",
      " [ 86  99]\n",
      " [ 93 101]\n",
      " [ 98 106]\n",
      " [ 91 105]\n",
      " [ 85 103]\n",
      " [127 111]\n",
      " [133 108]\n",
      " [139 110]\n",
      " [145 114]\n",
      " [139 114]\n",
      " [133 113]\n",
      " [ 80 148]\n",
      " [ 90 146]\n",
      " [ 99 146]\n",
      " [105 149]\n",
      " [113 149]\n",
      " [121 151]\n",
      " [129 156]\n",
      " [119 165]\n",
      " [109 167]\n",
      " [102 166]\n",
      " [ 95 164]\n",
      " [ 87 160]\n",
      " [ 83 149]\n",
      " [ 98 151]\n",
      " [105 152]\n",
      " [112 153]\n",
      " [126 156]\n",
      " [110 161]\n",
      " [103 160]\n",
      " [ 97 158]]\n",
      "[[ 49  96]\n",
      " [ 46 112]\n",
      " [ 46 128]\n",
      " [ 48 144]\n",
      " [ 55 158]\n",
      " [ 65 170]\n",
      " [ 77 181]\n",
      " [ 90 191]\n",
      " [104 195]\n",
      " [117 193]\n",
      " [128 184]\n",
      " [139 173]\n",
      " [149 161]\n",
      " [156 147]\n",
      " [161 133]\n",
      " [164 118]\n",
      " [164 104]\n",
      " [ 68  87]\n",
      " [ 77  84]\n",
      " [ 87  86]\n",
      " [ 96  89]\n",
      " [103  94]\n",
      " [128  95]\n",
      " [136  92]\n",
      " [144  89]\n",
      " [152  88]\n",
      " [158  93]\n",
      " [114 108]\n",
      " [114 120]\n",
      " [114 131]\n",
      " [113 143]\n",
      " [ 97 144]\n",
      " [104 147]\n",
      " [111 150]\n",
      " [118 148]\n",
      " [125 146]\n",
      " [ 76 103]\n",
      " [ 84 102]\n",
      " [ 90 104]\n",
      " [ 96 109]\n",
      " [ 89 107]\n",
      " [ 82 105]\n",
      " [129 110]\n",
      " [135 106]\n",
      " [141 105]\n",
      " [147 107]\n",
      " [142 109]\n",
      " [135 110]\n",
      " [ 83 156]\n",
      " [ 94 155]\n",
      " [104 154]\n",
      " [110 157]\n",
      " [116 155]\n",
      " [123 157]\n",
      " [131 159]\n",
      " [122 166]\n",
      " [115 170]\n",
      " [108 171]\n",
      " [101 169]\n",
      " [ 92 164]\n",
      " [ 87 157]\n",
      " [103 160]\n",
      " [109 161]\n",
      " [115 161]\n",
      " [127 160]\n",
      " [115 162]\n",
      " [109 163]\n",
      " [102 162]]\n",
      "[[ 30 116]\n",
      " [ 33 135]\n",
      " [ 35 154]\n",
      " [ 41 172]\n",
      " [ 52 188]\n",
      " [ 68 200]\n",
      " [ 86 209]\n",
      " [106 215]\n",
      " [125 217]\n",
      " [140 211]\n",
      " [150 200]\n",
      " [156 186]\n",
      " [161 169]\n",
      " [163 154]\n",
      " [164 137]\n",
      " [162 122]\n",
      " [159 109]\n",
      " [ 58 101]\n",
      " [ 68  93]\n",
      " [ 80  88]\n",
      " [ 94  87]\n",
      " [106  90]\n",
      " [121  91]\n",
      " [130  87]\n",
      " [141  87]\n",
      " [150  89]\n",
      " [155  96]\n",
      " [116 103]\n",
      " [119 114]\n",
      " [122 126]\n",
      " [124 138]\n",
      " [104 144]\n",
      " [112 147]\n",
      " [122 150]\n",
      " [129 147]\n",
      " [134 144]\n",
      " [ 74 108]\n",
      " [ 81 104]\n",
      " [ 88 104]\n",
      " [ 95 108]\n",
      " [ 88 108]\n",
      " [ 81 108]\n",
      " [127 106]\n",
      " [134 103]\n",
      " [141 102]\n",
      " [147 106]\n",
      " [141 107]\n",
      " [135 107]\n",
      " [ 88 164]\n",
      " [102 163]\n",
      " [113 163]\n",
      " [121 165]\n",
      " [127 163]\n",
      " [136 161]\n",
      " [144 161]\n",
      " [137 168]\n",
      " [129 171]\n",
      " [123 172]\n",
      " [114 172]\n",
      " [103 169]\n",
      " [ 92 164]\n",
      " [113 166]\n",
      " [121 166]\n",
      " [128 165]\n",
      " [141 162]\n",
      " [128 166]\n",
      " [122 168]\n",
      " [113 167]]\n",
      "[[ 57  88]\n",
      " [ 55 104]\n",
      " [ 55 119]\n",
      " [ 57 134]\n",
      " [ 61 149]\n",
      " [ 68 162]\n",
      " [ 77 174]\n",
      " [ 87 182]\n",
      " [ 97 185]\n",
      " [106 183]\n",
      " [116 176]\n",
      " [125 167]\n",
      " [133 157]\n",
      " [140 147]\n",
      " [146 136]\n",
      " [150 125]\n",
      " [153 113]\n",
      " [ 73  84]\n",
      " [ 82  82]\n",
      " [ 92  83]\n",
      " [101  87]\n",
      " [109  92]\n",
      " [127  95]\n",
      " [136  93]\n",
      " [143  93]\n",
      " [150  94]\n",
      " [154  99]\n",
      " [115 108]\n",
      " [114 119]\n",
      " [112 130]\n",
      " [110 141]\n",
      " [ 98 143]\n",
      " [103 146]\n",
      " [107 148]\n",
      " [112 148]\n",
      " [116 146]\n",
      " [ 81 100]\n",
      " [ 88  97]\n",
      " [ 96  99]\n",
      " [100 107]\n",
      " [ 93 107]\n",
      " [ 86 105]\n",
      " [125 111]\n",
      " [132 105]\n",
      " [139 105]\n",
      " [143 111]\n",
      " [139 114]\n",
      " [132 113]\n",
      " [ 86 156]\n",
      " [ 93 155]\n",
      " [100 154]\n",
      " [104 157]\n",
      " [109 156]\n",
      " [113 158]\n",
      " [117 160]\n",
      " [111 166]\n",
      " [106 168]\n",
      " [102 168]\n",
      " [ 97 167]\n",
      " [ 91 163]\n",
      " [ 89 157]\n",
      " [ 99 158]\n",
      " [104 160]\n",
      " [108 160]\n",
      " [114 161]\n",
      " [108 160]\n",
      " [103 160]\n",
      " [ 98 159]]\n",
      "[[ 52 101]\n",
      " [ 50 115]\n",
      " [ 47 130]\n",
      " [ 46 144]\n",
      " [ 49 157]\n",
      " [ 56 169]\n",
      " [ 66 178]\n",
      " [ 78 186]\n",
      " [ 91 190]\n",
      " [106 192]\n",
      " [120 188]\n",
      " [131 182]\n",
      " [141 173]\n",
      " [147 162]\n",
      " [151 151]\n",
      " [155 138]\n",
      " [157 127]\n",
      " [ 72  91]\n",
      " [ 80  83]\n",
      " [ 91  81]\n",
      " [102  82]\n",
      " [111  88]\n",
      " [126  93]\n",
      " [136  94]\n",
      " [146  97]\n",
      " [153 103]\n",
      " [154 112]\n",
      " [117 103]\n",
      " [115 110]\n",
      " [113 118]\n",
      " [112 125]\n",
      " [ 98 132]\n",
      " [103 134]\n",
      " [108 137]\n",
      " [113 138]\n",
      " [118 138]\n",
      " [ 83 100]\n",
      " [ 89  99]\n",
      " [ 94 101]\n",
      " [ 98 103]\n",
      " [ 92 103]\n",
      " [ 87 101]\n",
      " [127 111]\n",
      " [133 111]\n",
      " [138 112]\n",
      " [142 116]\n",
      " [137 114]\n",
      " [132 113]\n",
      " [ 83 148]\n",
      " [ 92 147]\n",
      " [100 147]\n",
      " [105 150]\n",
      " [109 150]\n",
      " [115 154]\n",
      " [119 158]\n",
      " [112 160]\n",
      " [105 158]\n",
      " [100 157]\n",
      " [ 95 155]\n",
      " [ 89 152]\n",
      " [ 86 149]\n",
      " [ 98 151]\n",
      " [103 152]\n",
      " [108 154]\n",
      " [116 157]\n",
      " [107 154]\n",
      " [102 153]\n",
      " [ 97 151]]\n",
      "[[ 42 120]\n",
      " [ 45 137]\n",
      " [ 50 153]\n",
      " [ 57 168]\n",
      " [ 66 182]\n",
      " [ 80 193]\n",
      " [ 96 200]\n",
      " [113 203]\n",
      " [129 203]\n",
      " [141 197]\n",
      " [149 186]\n",
      " [155 174]\n",
      " [158 160]\n",
      " [159 145]\n",
      " [160 132]\n",
      " [159 118]\n",
      " [156 105]\n",
      " [ 60 101]\n",
      " [ 67  92]\n",
      " [ 78  87]\n",
      " [ 91  86]\n",
      " [102  88]\n",
      " [123  85]\n",
      " [130  81]\n",
      " [139  81]\n",
      " [147  84]\n",
      " [151  90]\n",
      " [117 101]\n",
      " [120 108]\n",
      " [123 116]\n",
      " [126 125]\n",
      " [112 139]\n",
      " [118 139]\n",
      " [125 140]\n",
      " [129 138]\n",
      " [132 136]\n",
      " [ 76 110]\n",
      " [ 82 105]\n",
      " [ 90 104]\n",
      " [ 97 108]\n",
      " [ 90 110]\n",
      " [ 83 111]\n",
      " [126 105]\n",
      " [132 100]\n",
      " [138  99]\n",
      " [143 102]\n",
      " [139 105]\n",
      " [133 106]\n",
      " [ 95 164]\n",
      " [107 158]\n",
      " [117 155]\n",
      " [124 156]\n",
      " [129 154]\n",
      " [136 154]\n",
      " [141 158]\n",
      " [138 167]\n",
      " [132 172]\n",
      " [126 174]\n",
      " [119 174]\n",
      " [108 172]\n",
      " [ 99 164]\n",
      " [118 160]\n",
      " [124 160]\n",
      " [130 158]\n",
      " [138 158]\n",
      " [131 165]\n",
      " [124 167]\n",
      " [118 168]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/141 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 49 107]\n",
      " [ 51 123]\n",
      " [ 55 137]\n",
      " [ 60 151]\n",
      " [ 68 164]\n",
      " [ 79 174]\n",
      " [ 92 183]\n",
      " [107 190]\n",
      " [121 190]\n",
      " [134 186]\n",
      " [146 175]\n",
      " [156 163]\n",
      " [163 149]\n",
      " [167 135]\n",
      " [168 120]\n",
      " [167 105]\n",
      " [166  90]\n",
      " [ 63 103]\n",
      " [ 71  98]\n",
      " [ 80  95]\n",
      " [ 91  95]\n",
      " [100  98]\n",
      " [121  95]\n",
      " [129  89]\n",
      " [138  86]\n",
      " [147  85]\n",
      " [155  89]\n",
      " [112 106]\n",
      " [113 117]\n",
      " [114 127]\n",
      " [116 138]\n",
      " [106 144]\n",
      " [111 145]\n",
      " [117 145]\n",
      " [122 143]\n",
      " [127 140]\n",
      " [ 76 110]\n",
      " [ 82 108]\n",
      " [ 89 107]\n",
      " [ 96 109]\n",
      " [ 90 111]\n",
      " [ 83 113]\n",
      " [126 105]\n",
      " [132 101]\n",
      " [138 100]\n",
      " [144 101]\n",
      " [140 104]\n",
      " [133 106]\n",
      " [100 163]\n",
      " [107 159]\n",
      " [113 156]\n",
      " [118 157]\n",
      " [123 155]\n",
      " [129 155]\n",
      " [136 156]\n",
      " [132 162]\n",
      " [126 166]\n",
      " [121 167]\n",
      " [115 168]\n",
      " [108 166]\n",
      " [103 162]\n",
      " [114 160]\n",
      " [119 160]\n",
      " [124 158]\n",
      " [133 157]\n",
      " [125 158]\n",
      " [119 160]\n",
      " [114 160]]\n",
      "[[ 40  96]\n",
      " [ 40 114]\n",
      " [ 40 132]\n",
      " [ 45 148]\n",
      " [ 54 163]\n",
      " [ 65 174]\n",
      " [ 78 184]\n",
      " [ 93 190]\n",
      " [107 192]\n",
      " [117 189]\n",
      " [124 180]\n",
      " [130 169]\n",
      " [136 157]\n",
      " [141 144]\n",
      " [147 130]\n",
      " [150 117]\n",
      " [150 102]\n",
      " [ 64  92]\n",
      " [ 75  88]\n",
      " [ 86  87]\n",
      " [ 98  89]\n",
      " [110  92]\n",
      " [127  91]\n",
      " [134  88]\n",
      " [141  85]\n",
      " [148  83]\n",
      " [153  86]\n",
      " [117 107]\n",
      " [119 118]\n",
      " [121 129]\n",
      " [122 140]\n",
      " [107 146]\n",
      " [113 148]\n",
      " [119 149]\n",
      " [124 148]\n",
      " [127 145]\n",
      " [ 75 105]\n",
      " [ 84 100]\n",
      " [ 93 101]\n",
      " [ 99 109]\n",
      " [ 91 112]\n",
      " [ 82 111]\n",
      " [125 108]\n",
      " [131  99]\n",
      " [140  98]\n",
      " [145 102]\n",
      " [141 109]\n",
      " [132 110]\n",
      " [ 97 168]\n",
      " [105 163]\n",
      " [113 160]\n",
      " [117 161]\n",
      " [120 159]\n",
      " [125 162]\n",
      " [127 165]\n",
      " [124 170]\n",
      " [120 173]\n",
      " [116 174]\n",
      " [112 174]\n",
      " [105 172]\n",
      " [102 168]\n",
      " [113 166]\n",
      " [117 165]\n",
      " [120 165]\n",
      " [124 165]\n",
      " [120 165]\n",
      " [117 166]\n",
      " [113 166]]\n",
      "[[ 24 113]\n",
      " [ 26 135]\n",
      " [ 29 157]\n",
      " [ 37 178]\n",
      " [ 51 194]\n",
      " [ 68 208]\n",
      " [ 87 219]\n",
      " [106 226]\n",
      " [122 226]\n",
      " [134 219]\n",
      " [141 204]\n",
      " [146 188]\n",
      " [151 172]\n",
      " [155 155]\n",
      " [157 138]\n",
      " [155 122]\n",
      " [152 107]\n",
      " [ 57 102]\n",
      " [ 67  93]\n",
      " [ 81  89]\n",
      " [ 94  89]\n",
      " [108  92]\n",
      " [127  92]\n",
      " [134  89]\n",
      " [142  87]\n",
      " [148  87]\n",
      " [152  91]\n",
      " [121 105]\n",
      " [124 116]\n",
      " [128 127]\n",
      " [132 139]\n",
      " [108 148]\n",
      " [118 150]\n",
      " [126 152]\n",
      " [133 150]\n",
      " [137 146]\n",
      " [ 74 109]\n",
      " [ 82 104]\n",
      " [ 91 103]\n",
      " [ 97 108]\n",
      " [ 91 110]\n",
      " [ 83 111]\n",
      " [127 106]\n",
      " [133 101]\n",
      " [141 100]\n",
      " [145 104]\n",
      " [141 107]\n",
      " [134 107]\n",
      " [ 85 167]\n",
      " [100 162]\n",
      " [114 160]\n",
      " [121 162]\n",
      " [128 160]\n",
      " [134 161]\n",
      " [137 165]\n",
      " [134 179]\n",
      " [128 188]\n",
      " [120 190]\n",
      " [112 190]\n",
      " [ 98 183]\n",
      " [ 88 167]\n",
      " [113 165]\n",
      " [121 165]\n",
      " [128 164]\n",
      " [134 166]\n",
      " [127 178]\n",
      " [121 180]\n",
      " [112 180]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 225 is out of bounds for dimension 0 with size 224",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mIndexError\u001B[0m                                Traceback (most recent call last)",
      "Input \u001B[1;32mIn [11]\u001B[0m, in \u001B[0;36m<cell line: 8>\u001B[1;34m()\u001B[0m\n\u001B[0;32m      8\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m epoch \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(epochs):\n\u001B[0;32m      9\u001B[0m     train_running_loss \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0.0\u001B[39m\n\u001B[1;32m---> 10\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m i, data \u001B[38;5;129;01min\u001B[39;00m tqdm(\u001B[38;5;28menumerate\u001B[39m(train_loader_classification), total\u001B[38;5;241m=\u001B[39m(\u001B[38;5;28mlen\u001B[39m(train_loader_classification))):\n\u001B[0;32m     11\u001B[0m         images, keypoints \u001B[38;5;241m=\u001B[39m data[\u001B[38;5;241m0\u001B[39m]\u001B[38;5;241m.\u001B[39mto(device, dtype\u001B[38;5;241m=\u001B[39mtorch\u001B[38;5;241m.\u001B[39mfloat32), data[\u001B[38;5;241m1\u001B[39m]\u001B[38;5;241m.\u001B[39mto(device, dtype\u001B[38;5;241m=\u001B[39mtorch\u001B[38;5;241m.\u001B[39mfloat32)\n\u001B[0;32m     12\u001B[0m         preds \u001B[38;5;241m=\u001B[39m model(images)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\pytorch_tutorial\\lib\\site-packages\\tqdm\\std.py:1195\u001B[0m, in \u001B[0;36mtqdm.__iter__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m   1192\u001B[0m time \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_time\n\u001B[0;32m   1194\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m-> 1195\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m obj \u001B[38;5;129;01min\u001B[39;00m iterable:\n\u001B[0;32m   1196\u001B[0m         \u001B[38;5;28;01myield\u001B[39;00m obj\n\u001B[0;32m   1197\u001B[0m         \u001B[38;5;66;03m# Update and possibly print the progressbar.\u001B[39;00m\n\u001B[0;32m   1198\u001B[0m         \u001B[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\pytorch_tutorial\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:652\u001B[0m, in \u001B[0;36m_BaseDataLoaderIter.__next__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    649\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sampler_iter \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    650\u001B[0m     \u001B[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001B[39;00m\n\u001B[0;32m    651\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_reset()  \u001B[38;5;66;03m# type: ignore[call-arg]\u001B[39;00m\n\u001B[1;32m--> 652\u001B[0m data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_next_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    653\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[0;32m    654\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_dataset_kind \u001B[38;5;241m==\u001B[39m _DatasetKind\u001B[38;5;241m.\u001B[39mIterable \u001B[38;5;129;01mand\u001B[39;00m \\\n\u001B[0;32m    655\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m \\\n\u001B[0;32m    656\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m>\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called:\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\pytorch_tutorial\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:692\u001B[0m, in \u001B[0;36m_SingleProcessDataLoaderIter._next_data\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    690\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_next_data\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m    691\u001B[0m     index \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_next_index()  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[1;32m--> 692\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_dataset_fetcher\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfetch\u001B[49m\u001B[43m(\u001B[49m\u001B[43mindex\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[0;32m    693\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pin_memory:\n\u001B[0;32m    694\u001B[0m         data \u001B[38;5;241m=\u001B[39m _utils\u001B[38;5;241m.\u001B[39mpin_memory\u001B[38;5;241m.\u001B[39mpin_memory(data, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pin_memory_device)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\pytorch_tutorial\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:49\u001B[0m, in \u001B[0;36m_MapDatasetFetcher.fetch\u001B[1;34m(self, possibly_batched_index)\u001B[0m\n\u001B[0;32m     47\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mfetch\u001B[39m(\u001B[38;5;28mself\u001B[39m, possibly_batched_index):\n\u001B[0;32m     48\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mauto_collation:\n\u001B[1;32m---> 49\u001B[0m         data \u001B[38;5;241m=\u001B[39m [\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset[idx] \u001B[38;5;28;01mfor\u001B[39;00m idx \u001B[38;5;129;01min\u001B[39;00m possibly_batched_index]\n\u001B[0;32m     50\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m     51\u001B[0m         data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset[possibly_batched_index]\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\pytorch_tutorial\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:49\u001B[0m, in \u001B[0;36m<listcomp>\u001B[1;34m(.0)\u001B[0m\n\u001B[0;32m     47\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mfetch\u001B[39m(\u001B[38;5;28mself\u001B[39m, possibly_batched_index):\n\u001B[0;32m     48\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mauto_collation:\n\u001B[1;32m---> 49\u001B[0m         data \u001B[38;5;241m=\u001B[39m [\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdataset\u001B[49m\u001B[43m[\u001B[49m\u001B[43midx\u001B[49m\u001B[43m]\u001B[49m \u001B[38;5;28;01mfor\u001B[39;00m idx \u001B[38;5;129;01min\u001B[39;00m possibly_batched_index]\n\u001B[0;32m     50\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m     51\u001B[0m         data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset[possibly_batched_index]\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\pytorch_tutorial\\lib\\site-packages\\torch\\utils\\data\\dataset.py:290\u001B[0m, in \u001B[0;36mSubset.__getitem__\u001B[1;34m(self, idx)\u001B[0m\n\u001B[0;32m    288\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(idx, \u001B[38;5;28mlist\u001B[39m):\n\u001B[0;32m    289\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset[[\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mindices[i] \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m idx]]\n\u001B[1;32m--> 290\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdataset\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mindices\u001B[49m\u001B[43m[\u001B[49m\u001B[43midx\u001B[49m\u001B[43m]\u001B[49m\u001B[43m]\u001B[49m\n",
      "Input \u001B[1;32mIn [9]\u001B[0m, in \u001B[0;36mFlickrDatasetClassification.__getitem__\u001B[1;34m(self, idx)\u001B[0m\n\u001B[0;32m     21\u001B[0m new_keypoints \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mzeros(\u001B[38;5;241m68\u001B[39m, \u001B[38;5;241m224\u001B[39m, \u001B[38;5;241m224\u001B[39m)\n\u001B[0;32m     22\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;28mlen\u001B[39m(new_keypoints)):\n\u001B[1;32m---> 23\u001B[0m     new_keypoints[i][keypoints[i][\u001B[38;5;241m0\u001B[39m] \u001B[38;5;241m-\u001B[39m \u001B[38;5;241m1\u001B[39m][keypoints[i][\u001B[38;5;241m1\u001B[39m] \u001B[38;5;241m-\u001B[39m \u001B[38;5;241m1\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[0;32m     24\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtransform:\n\u001B[0;32m     25\u001B[0m     image \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtransform(image)\n",
      "\u001B[1;31mIndexError\u001B[0m: index 225 is out of bounds for dimension 0 with size 224"
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "#model = ClassificationCNN().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "train_loss = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    train_running_loss = 0.0\n",
    "    for i, data in tqdm(enumerate(train_loader_classification), total=(len(train_loader_classification))):\n",
    "        images, keypoints = data[0].to(device, dtype=torch.float32), data[1].to(device, dtype=torch.float32)\n",
    "        preds = model(images)\n",
    "        print(preds.size())\n",
    "        print(keypoints.size())\n",
    "        loss = criterion(preds, keypoints)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        train_running_loss += loss.item()\n",
    "    train_loss.append(train_running_loss / (ceil(len(train_dataset) / batch_size)))\n",
    "\n",
    "    #model.eval()\n",
    "\n",
    "    #with torch.no_grad():\n",
    "    #    val_running_loss = 0.0\n",
    "    #    for i, data in tqdm(enumerate(val_loader), total=(len(val_loader))):\n",
    "    #        image, keypoints = data[0].to(device), data[1].to(device)\n",
    "    #        preds = model(image)\n",
    "    #        loss = criterion(preds, keypoints)\n",
    "    #        val_running_loss += loss.item()\n",
    "    #    val_loss.append(val_running_loss / ceil(len(val_dataset) / batch_size))\n",
    "    print(f'Epoch: {epoch + 1}')\n",
    "    print(f'Train_loss at epoch {epoch + 1}: {train_loss[-1]}')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,7))\n",
    "plt.plot(train_loss, label=\"train\")\n",
    "plt.xlabel(\"iterations\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pytorch_tutorial",
   "language": "python",
   "display_name": "pytorch_tutorial"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}